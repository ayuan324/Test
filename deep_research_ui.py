import streamlit as st
import time
import asyncio
from deep_research import cell, create_llm # å¯¼å…¥ cell å’Œæ–°çš„ create_llm
import json # å¯¼å…¥ json

# è®¾ç½®é¡µé¢é…ç½®
st.set_page_config(page_title="Deep Research æ™ºèƒ½ç ”ç©¶åŠ©æ‰‹", layout="wide")
st.title("ğŸ“Š Deep Research æ™ºèƒ½ç ”ç©¶åŠ©æ‰‹")

# åˆå§‹åŒ– session_state (å¢åŠ  LLM é…ç½®)
if 'start_time' not in st.session_state:
    st.session_state['start_time'] = 0
if 'token_total' not in st.session_state:
    st.session_state['token_total'] = 0
if 'steps' not in st.session_state:
    st.session_state['steps'] = [] # å­˜å‚¨ (step_name, content, token_used, time_taken)
if 'final_report' not in st.session_state:
    st.session_state['final_report'] = None
if 'running' not in st.session_state:
    st.session_state['running'] = False
# LLM é»˜è®¤é…ç½®
if 'selected_model' not in st.session_state:
    st.session_state['selected_model'] = "qwen-max"
if 'temperature' not in st.session_state:
    st.session_state['temperature'] = 0.7

# UI å›è°ƒå‡½æ•° (ä¿®æ”¹å)
def ui_callback(step_name, content, token_used=0, time_taken=0):
    """ç”¨äºä»åç«¯é€»è¾‘æ¥æ”¶æ›´æ–°å¹¶æ˜¾ç¤ºåœ¨UIä¸Š (ä¸å†è°ƒç”¨ rerun)"""
    st.session_state['steps'].append((step_name, content, token_used, time_taken))
    st.session_state['token_total'] += token_used
    # æ³¨æ„ï¼šè¿™é‡Œä¸å†è°ƒç”¨ st.rerun()ã€‚UI æ›´æ–°å°†ä¾èµ–äº Streamlit çš„è‡ªç„¶æµç¨‹
    # æˆ–é€šè¿‡æ›´æ–°ä¸‹é¢çš„ placeholder å®ç°ã€‚

# --- UI å¸ƒå±€ ---
col1, col2 = st.columns([2, 1]) # ä¸»å†…å®¹åŒºå’Œä¾§è¾¹æ 

with col1:
    st.header("ç ”ç©¶è¿‡ç¨‹")
    # è¾“å…¥åŒºåŸŸ
    query = st.text_input("è¯·è¾“å…¥ä½ çš„ç ”ç©¶é—®é¢˜ï¼š", key="query_input", disabled=st.session_state['running'])
    start_btn = st.button("ğŸš€ å¼€å§‹åˆ†æ", key="start_button", disabled=st.session_state['running'] or not query)

    # è¿‡ç¨‹å±•ç¤ºåŒº (ä½¿ç”¨ placeholder)
    steps_placeholder = st.empty() # åˆ›å»ºä¸€ä¸ªç©ºå ä½ç¬¦

    # æœ€ç»ˆæŠ¥å‘ŠåŒº
    if st.session_state['final_report']:
        st.header("âœ… æœ€ç»ˆæŠ¥å‘Š")
        st.markdown(st.session_state['final_report'])

with col2:
    st.header("é…ç½®")
    # --- LLM é…ç½® UI --- (æ–°å¢)
    st.selectbox(
        "é€‰æ‹©è¯­è¨€æ¨¡å‹:",
        options=["qwen-max", "deepseek-chat", "azure-gpt-4o"], # å¯é€‰æ¨¡å‹åˆ—è¡¨
        key="selected_model",
        disabled=st.session_state['running'],
        help="ç¡®ä¿æ‰€é€‰æ¨¡å‹çš„ API Key å’Œ Endpoint å·²åœ¨ç¯å¢ƒä¸­æ­£ç¡®é…ç½®ã€‚"
    )
    st.slider(
        "æ¨¡å‹æ¸©åº¦ (Temperature):",
        min_value=0.0,
        max_value=1.0,
        step=0.05,
        key="temperature",
        disabled=st.session_state['running'],
        help="å€¼è¶Šé«˜ï¼Œè¾“å‡ºè¶Šéšæœºï¼›å€¼è¶Šä½ï¼Œè¾“å‡ºè¶Šç¡®å®šã€‚"
    )
    st.markdown("---") # åˆ†éš”çº¿
    # ---------------------

    st.header("ç»Ÿè®¡ä¿¡æ¯")
    # ç»Ÿè®¡ä¿¡æ¯åŒº (ä½¿ç”¨ placeholder ä¿è¯å®æ—¶æ›´æ–°)
    stats_placeholder = st.empty()

    st.info("Agent ä¼šé€æ­¥åˆ†è§£ä»»åŠ¡ã€æœç´¢ä¿¡æ¯å¹¶ç”ŸæˆæŠ¥å‘Šã€‚")

# --- åç«¯é€»è¾‘è°ƒç”¨ ---
if start_btn and query and not st.session_state['running']:
    # é‡ç½®çŠ¶æ€
    st.session_state['start_time'] = time.time()
    st.session_state['token_total'] = 0
    st.session_state['steps'] = []
    st.session_state['final_report'] = None
    st.session_state['running'] = True
    st.rerun() # ä»…åœ¨å¼€å§‹æ—¶ rerun ä¸€æ¬¡ä»¥ç¦ç”¨è¾“å…¥

elif st.session_state['running'] and not st.session_state['final_report']:
    try:
        loop = asyncio.get_event_loop()
    except RuntimeError as ex:
        if "There is no current event loop in thread" in str(ex):
            loop = asyncio.new_event_loop()
            asyncio.set_event_loop(loop)
        else:
            raise ex

    query_to_run = st.session_state['query_input']
    with st.spinner("ğŸ¤– Agent æ­£åœ¨å·¥ä½œä¸­ï¼Œè¯·ç¨å€™..."):
        # åœ¨è°ƒç”¨ cell ä¹‹å‰ï¼Œæ›´æ–°ä¸€æ¬¡ç»Ÿè®¡ä¿¡æ¯
        with stats_placeholder.container():
            total_time = time.time() - st.session_state.get('start_time', time.time())
            st.metric("æ€»è€—æ—¶", f"{total_time:.2f} ç§’")
            st.metric("æ€»Tokenæ¶ˆè€—", f"{st.session_state.get('token_total', 0)}")

        try:
            # --- åˆ›å»º LLM å®ä¾‹ (æ–°å¢) ---
            try:
                current_model = create_llm(
                    model_name=st.session_state['selected_model'],
                    temperature=st.session_state['temperature']
                    # å¦‚éœ€ä¼ é€’ max_tokens ç­‰ï¼Œå¯åœ¨æ­¤å¤„æ·»åŠ 
                )
            except Exception as model_creation_error:
                st.error(f"åˆ›å»ºè¯­è¨€æ¨¡å‹å¤±è´¥: {model_creation_error}")
                st.session_state['running'] = False
                st.rerun()
                st.stop() # åœæ­¢è„šæœ¬æ‰§è¡Œ
            # ---------------------------

            # å®šä¹‰ä¸€ä¸ªåŒ…è£…å›è°ƒï¼Œç”¨äºæ›´æ–° placeholder (ä¿®æ”¹å†…éƒ¨é€»è¾‘)
            def update_ui_display(*args):
                ui_callback(*args) # å…ˆç”¨æ—§å›è°ƒæ›´æ–° state

                # -- Helper to get emoji based on step name --
                def get_step_emoji(step_name):
                    name_lower = step_name.lower()
                    if "å¤±è´¥" in name_lower or "é”™è¯¯" in name_lower:
                        return "âš ï¸"
                    elif "ç»†åŒ–ä»»åŠ¡ä¸­" in name_lower:
                        return "ğŸ§ "
                    elif "ä»»åŠ¡ç»†åŒ–å®Œæˆ" in name_lower:
                        return "ğŸ§©"
                    elif "å¤„ç†å­ä»»åŠ¡" in name_lower:
                        return "âš™ï¸"
                    elif "å…³é”®è¯" in name_lower:
                        return "ğŸ”‘"
                    elif "æŸ¥æ‰¾ä¿¡æ¯ (tavily)" in name_lower:
                        return "ğŸ”"
                    elif "æŸ¥æ‰¾ä¿¡æ¯å®Œæˆ" in name_lower:
                        return "ğŸ“„"
                    elif "æ€»ç»“æ‰€æœ‰ä¿¡æ¯" in name_lower:
                        return "âœï¸"
                    elif "ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š" in name_lower:
                        return "âœ…"
                    else:
                        return "â¡ï¸" # Default

                # æ›´æ–°æ­¥éª¤æ˜¾ç¤ºåŒºåŸŸ (ä½¿ç”¨ expander)
                with steps_placeholder.container():
                    st.subheader("æ€è€ƒè¿‡ç¨‹é“¾") # å¯ä»¥åŠ ä¸ªæ ‡é¢˜
                    if not st.session_state['steps']:
                        st.write("ç­‰å¾… Agent å¼€å§‹...")
                    else:
                        num_steps = len(st.session_state['steps'])
                        # åå‘éå†æ­¥éª¤åˆ—è¡¨
                        for i in range(num_steps - 1, -1, -1):
                            s_name, s_content, s_tokens, s_time = st.session_state['steps'][i]
                            # is_last_step åœ¨åå‘éå†ä¸­å˜ä¸º is_first_displayed_step
                            is_newest_step = (i == num_steps - 1)
                            emoji = get_step_emoji(s_name)
                            # æ ‡ç­¾ç°åœ¨ä½¿ç”¨åå‘è®¡æ•°æˆ–ä¿æŒæ­£å‘è®¡æ•°ï¼Ÿä¿æŒæ­£å‘æ˜“äºç†è§£
                            expander_label = f"{emoji} {i + 1}. {s_name}" # ä¿æŒåŸæœ‰ç¼–å·
                            with st.expander(expander_label, expanded=is_newest_step):
                                # åœ¨å±•å¼€å†…å®¹ä¸­æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯å’Œè€—æ—¶/token
                                st.markdown(f"_è€—æ—¶: {s_time:.2f}s | Tokens: {s_tokens}_ ")
                                st.markdown("---") # åˆ†éš”ç¬¦
                                if isinstance(s_content, (dict, list)):
                                    try:
                                        st.code(json.dumps(s_content, ensure_ascii=False, indent=2), language='json')
                                    except TypeError:
                                        st.write(s_content) # å›é€€æ˜¾ç¤ºåŸå§‹æ ¼å¼
                                else:
                                    st.markdown(s_content)

                # æ›´æ–°ç»Ÿè®¡ä¿¡æ¯åŒºåŸŸ
                with stats_placeholder.container():
                    total_time = time.time() - st.session_state.get('start_time', time.time())
                    st.metric("æ€»è€—æ—¶", f"{total_time:.2f} ç§’")
                    st.metric("æ€»Tokenæ¶ˆè€—", f"{st.session_state.get('token_total', 0)}")

            # è¿è¡Œ cellï¼Œä¼ å…¥é…ç½®å¥½çš„ LLM å®ä¾‹
            result = loop.run_until_complete(cell(current_model, query_to_run, ui_callback=update_ui_display))
            st.session_state['final_report'] = result['report']
            st.session_state['running'] = False
            st.rerun() # ä»»åŠ¡å®Œæˆå rerun ä»¥æ˜¾ç¤ºæœ€ç»ˆæŠ¥å‘Šå¹¶è§£é”è¾“å…¥
        except Exception as e:
            st.error(f"åˆ†æè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
            st.session_state['running'] = False
            st.rerun()
else:
     # å¦‚æœæ²¡æœ‰è¿è¡Œï¼Œä¹Ÿæ˜¾ç¤ºä¸€æ¬¡ç»Ÿè®¡ä¿¡æ¯
     with stats_placeholder.container():
         total_time = time.time() - st.session_state.get('start_time', 0)
         st.metric("æ€»è€—æ—¶", f"{total_time:.2f} ç§’" if st.session_state.get('start_time', 0) > 0 else "N/A")
         st.metric("æ€»Tokenæ¶ˆè€—", f"{st.session_state.get('token_total', 0)}")
     # æ¸…ç©ºæ­¥éª¤åŒºåŸŸå¦‚æœä¸åœ¨è¿è¡Œä¸­ä¸”æ²¡æœ‰æœ€ç»ˆæŠ¥å‘Š
     if not st.session_state['running'] and not st.session_state['final_report']:
         steps_placeholder.empty() 